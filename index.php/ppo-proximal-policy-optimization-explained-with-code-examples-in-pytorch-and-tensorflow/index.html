<!DOCTYPE html>
<html lang="en-US">

<head>
	
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
	<link rel="profile" href="http://gmpg.org/xfn/11">
			<link rel="pingback" href="http://localhost:8000/xmlrpc.php">
		<title>PPO (Proximal Policy Optimization) Explained with Code Examples in PyTorch and Tensorflow &#8211; PlainSwipe</title>
<meta name='robots' content='max-image-preview:large' />
<link rel="alternate" type="application/rss+xml" title="PlainSwipe &raquo; Feed" href="../feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="PlainSwipe &raquo; Comments Feed" href="../comments/feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="PlainSwipe &raquo; PPO (Proximal Policy Optimization) Explained with Code Examples in PyTorch and Tensorflow Comments Feed" href="feed/index.html" />
<script type="text/javascript">
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/14.0.0\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/14.0.0\/svg\/","svgExt":".svg","source":{"concatemoji":"http:\/\/localhost:8000\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.2"}};
/*! This file is auto-generated */
!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){p.clearRect(0,0,i.width,i.height),p.fillText(e,0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(t,0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(p&&p.fillText)switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s("\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f","\ud83c\udff3\ufe0f\u200b\u26a7\ufe0f")?!1:!s("\ud83c\uddfa\ud83c\uddf3","\ud83c\uddfa\u200b\ud83c\uddf3")&&!s("\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f","\ud83c\udff4\u200b\udb40\udc67\u200b\udb40\udc62\u200b\udb40\udc65\u200b\udb40\udc6e\u200b\udb40\udc67\u200b\udb40\udc7f");case"emoji":return!s("\ud83e\udef1\ud83c\udffb\u200d\ud83e\udef2\ud83c\udfff","\ud83e\udef1\ud83c\udffb\u200b\ud83e\udef2\ud83c\udfff")}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(e=t.source||{}).concatemoji?c(e.concatemoji):e.wpemoji&&e.twemoji&&(c(e.twemoji),c(e.wpemoji)))}(window,document,window._wpemojiSettings);
</script>
<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 0.07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='wp-block-library-css' href='../../wp-includes/css/dist/block-library/style.min.css%3Fver=6.2.css' type='text/css' media='all' />
<link rel='stylesheet' id='classic-theme-styles-css' href='../../wp-includes/css/classic-themes.min.css%3Fver=6.2.css' type='text/css' media='all' />
<style id='global-styles-inline-css' type='text/css'>
body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--color--neve-link-color: var(--nv-primary-accent);--wp--preset--color--neve-link-hover-color: var(--nv-secondary-accent);--wp--preset--color--nv-site-bg: var(--nv-site-bg);--wp--preset--color--nv-light-bg: var(--nv-light-bg);--wp--preset--color--nv-dark-bg: var(--nv-dark-bg);--wp--preset--color--neve-text-color: var(--nv-text-color);--wp--preset--color--nv-text-dark-bg: var(--nv-text-dark-bg);--wp--preset--color--nv-c-1: var(--nv-c-1);--wp--preset--color--nv-c-2: var(--nv-c-2);--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--duotone--dark-grayscale: url('../../index.html%3Fp=942.html');--wp--preset--duotone--grayscale: url('../../index.html%3Fp=942.html');--wp--preset--duotone--purple-yellow: url('../../index.html%3Fp=942.html');--wp--preset--duotone--blue-red: url('../../index.html%3Fp=942.html');--wp--preset--duotone--midnight: url('../../index.html%3Fp=942.html');--wp--preset--duotone--magenta-yellow: url('../../index.html%3Fp=942.html');--wp--preset--duotone--purple-green: url('../../index.html%3Fp=942.html');--wp--preset--duotone--blue-orange: url('../../index.html%3Fp=942.html');--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}:where(.is-layout-flex){gap: 0.5em;}body .is-layout-flow > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}body .is-layout-flow > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}body .is-layout-flow > .aligncenter{margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}body .is-layout-constrained > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}body .is-layout-constrained > .aligncenter{margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > :where(:not(.alignleft):not(.alignright):not(.alignfull)){max-width: var(--wp--style--global--content-size);margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > .alignwide{max-width: var(--wp--style--global--wide-size);}body .is-layout-flex{display: flex;}body .is-layout-flex{flex-wrap: wrap;align-items: center;}body .is-layout-flex > *{margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
.wp-block-navigation a:where(:not(.wp-element-button)){color: inherit;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}
.wp-block-pullquote{font-size: 1.5em;line-height: 1.6;}
</style>
<link rel='stylesheet' id='neve-style-css' href='../../wp-content/themes/neve/style-main-new.min.css%3Fver=3.4.4.css' type='text/css' media='all' />
<style id='neve-style-inline-css' type='text/css'>
.nv-meta-list li.meta:not(:last-child):after { content:"/" }.nv-meta-list .no-mobile{
			display:none;
		}.nv-meta-list li.last::after{
			content: ""!important;
		}@media (min-width: 769px) {
			.nv-meta-list .no-mobile {
				display: inline-block;
			}
			.nv-meta-list li.last:not(:last-child)::after {
		 		content: "/" !important;
			}
		}
 :root{ --container: 748px;--postwidth:100%; --primarybtnbg: var(--nv-primary-accent); --secondarybtnbg: rgba(0, 0, 0, 0); --primarybtnhoverbg: var(--nv-secondary-accent); --secondarybtnhoverbg: var(--nv-dark-bg); --primarybtncolor: #010101; --secondarybtncolor: var(--nv-dark-bg); --primarybtnhovercolor: #ffffff; --secondarybtnhovercolor: var(--nv-text-dark-bg);--primarybtnborderradius:0;--secondarybtnborderradius:0;--secondarybtnborderwidth:2px;--btnpadding:12px 24px;--primarybtnpadding:12px 24px;--secondarybtnpadding:10px 22px; --btnfs: 14px; --btnlineheight: 1.6em; --bodyfontfamily: Arial,Helvetica,sans-serif; --bodyfontsize: 16px; --bodylineheight: 1.7em; --bodyletterspacing: 0px; --bodyfontweight: 400; --bodytexttransform: none; --h1fontsize: 39px; --h1fontweight: 600; --h1lineheight: 1.2em; --h1letterspacing: 0px; --h1texttransform: none; --h2fontsize: 28px; --h2fontweight: 600; --h2lineheight: 1.3em; --h2letterspacing: 0px; --h2texttransform: none; --h3fontsize: 20px; --h3fontweight: 600; --h3lineheight: 1.3em; --h3letterspacing: 0px; --h3texttransform: none; --h4fontsize: 16px; --h4fontweight: 600; --h4lineheight: 1.3em; --h4letterspacing: 0px; --h4texttransform: none; --h5fontsize: 14px; --h5fontweight: 600; --h5lineheight: 1.3em; --h5letterspacing: 0px; --h5texttransform: none; --h6fontsize: 14px; --h6fontweight: 600; --h6lineheight: 1.3em; --h6letterspacing: 0px; --h6texttransform: none;--formfieldborderwidth:2px;--formfieldborderradius:0; --formfieldbgcolor: var(--nv-site-bg); --formfieldbordercolor: var(--nv-light-bg); --formfieldcolor: var(--nv-text-color);--formfieldpadding:10px 12px 10px 12px;; } .has-neve-button-color-color{ color: var(--nv-primary-accent)!important; } .has-neve-button-color-background-color{ background-color: var(--nv-primary-accent)!important; } .single-post-container .alignfull > [class*="__inner-container"], .single-post-container .alignwide > [class*="__inner-container"]{ max-width:718px } .nv-meta-list{ --avatarsize: 20px; } .single .nv-meta-list{ --avatarsize: 20px; } .blog .blog-entry-title, .archive .blog-entry-title{ --fontsize: 28px; } .single h1.entry-title{ --fontsize: 28px; } .nv-post-thumbnail-wrap{ --boxshadow:0 3px 6px -5px rgba(0, 0, 0, 0.1), 0 4px 8px rgba(0, 0, 0, 0.1); } .nv-post-cover{ --height: 250px;--padding:40px 15px;--justify: flex-start; --textalign: left; --valign: center; } .nv-post-cover .nv-title-meta-wrap, .nv-page-title-wrap, .entry-header{ --color: var(--nv-text-dark-bg); --textalign: left; } .nv-is-boxed.nv-title-meta-wrap{ --padding:40px 15px; --bgcolor: var(--nv-dark-bg); } .nv-overlay{ --bgcolor: var(--nv-dark-bg); --opacity: 50; --blendmode: normal; } .nv-is-boxed.nv-comments-wrap{ --padding:20px; } .nv-is-boxed.comment-respond{ --padding:20px; } .global-styled{ --bgcolor: var(--nv-site-bg); } .header-top{ --rowbcolor: var(--nv-light-bg); --color: var(--nv-text-color); --bgcolor: #f0f0f0; } .header-main{ --rowbcolor: var(--nv-light-bg); --color: var(--nv-text-color); --bgcolor: var(--nv-site-bg); } .header-bottom{ --rowbcolor: var(--nv-light-bg); --color: var(--nv-text-color); --bgcolor: #ffffff; } .header-menu-sidebar-bg{ --justify: flex-start; --textalign: left;--flexg: 1;--wrapdropdownwidth: auto; --color: var(--nv-text-color); --bgcolor: var(--nv-site-bg); } .header-menu-sidebar{ width: 360px; } .builder-item--logo{ --maxwidth: 32px;--padding:10px 0;--margin:0; --textalign: left;--justify: flex-start; } .builder-item--nav-icon,.header-menu-sidebar .close-sidebar-panel .navbar-toggle{ --borderradius:0;--borderwidth:1px; } .builder-item--nav-icon{ --label-margin:0 5px 0 0;;--padding:10px 15px;--margin:0; } .builder-item--primary-menu{ --color: var(--nv-text-color); --hovercolor: var(--nv-secondary-accent); --activecolor: var(--nv-text-color); --spacing: 20px; --height: 25px;--padding:0;--margin:0; --fontsize: 1em; --lineheight: 1.6; --letterspacing: 0px; --fontweight: 600; --texttransform: uppercase; --iconsize: 1em; } .hfg-is-group.has-primary-menu .inherit-ff{ --inheritedfw: 600; } .footer-top-inner .row{ grid-template-columns:1fr 1fr 1fr; --valign: flex-start; } .footer-top{ --rowbcolor: var(--nv-light-bg); --color: var(--nv-text-color); --bgcolor: #ffffff; } .footer-main-inner .row{ grid-template-columns:1fr 1fr 1fr; --valign: flex-start; } .footer-main{ --rowbcolor: var(--nv-light-bg); --color: var(--nv-text-color); --bgcolor: var(--nv-site-bg); } .footer-bottom-inner .row{ grid-template-columns:1fr 1fr 1fr; --valign: flex-start; } .footer-bottom{ --rowbcolor: var(--nv-light-bg); --color: var(--nv-text-dark-bg); --bgcolor: #000000; } @media(min-width: 576px){ :root{ --container: 992px;--postwidth:50%;--btnpadding:12px 24px;--primarybtnpadding:12px 24px;--secondarybtnpadding:10px 22px; --btnfs: 14px; --btnlineheight: 1.6em; --bodyfontsize: 16px; --bodylineheight: 1.7em; --bodyletterspacing: 0px; --h1fontsize: 55px; --h1lineheight: 1.3em; --h1letterspacing: 0px; --h2fontsize: 34px; --h2lineheight: 1.3em; --h2letterspacing: 0px; --h3fontsize: 20px; --h3lineheight: 1.3em; --h3letterspacing: 0px; --h4fontsize: 16px; --h4lineheight: 1.3em; --h4letterspacing: 0px; --h5fontsize: 14px; --h5lineheight: 1.3em; --h5letterspacing: 0px; --h6fontsize: 14px; --h6lineheight: 1.3em; --h6letterspacing: 0px; } .single-post-container .alignfull > [class*="__inner-container"], .single-post-container .alignwide > [class*="__inner-container"]{ max-width:962px } .nv-meta-list{ --avatarsize: 20px; } .single .nv-meta-list{ --avatarsize: 20px; } .blog .blog-entry-title, .archive .blog-entry-title{ --fontsize: 32px; } .single h1.entry-title{ --fontsize: 40px; } .nv-post-cover{ --height: 30vh;--padding:60px 30px;--justify: flex-start; --textalign: left; --valign: center; } .nv-post-cover .nv-title-meta-wrap, .nv-page-title-wrap, .entry-header{ --textalign: left; } .nv-is-boxed.nv-title-meta-wrap{ --padding:60px 30px; } .nv-is-boxed.nv-comments-wrap{ --padding:30px; } .nv-is-boxed.comment-respond{ --padding:30px; } .header-menu-sidebar-bg{ --justify: flex-start; --textalign: left;--flexg: 1;--wrapdropdownwidth: auto; } .header-menu-sidebar{ width: 360px; } .builder-item--logo{ --maxwidth: 32px;--padding:10px 0;--margin:0; --textalign: left;--justify: flex-start; } .builder-item--nav-icon{ --label-margin:0 5px 0 0;;--padding:10px 15px;--margin:0; } .builder-item--primary-menu{ --spacing: 20px; --height: 25px;--padding:0;--margin:0; --fontsize: 1em; --lineheight: 1.6; --letterspacing: 0px; --iconsize: 1em; } }@media(min-width: 960px){ :root{ --container: 1170px;--postwidth:50%;--btnpadding:12px 24px;--primarybtnpadding:12px 24px;--secondarybtnpadding:10px 22px; --btnfs: 16px; --btnlineheight: 1.6em; --bodyfontsize: 17px; --bodylineheight: 1.7em; --bodyletterspacing: 0px; --h1fontsize: 70px; --h1lineheight: 1.3em; --h1letterspacing: 0px; --h2fontsize: 46px; --h2lineheight: 1.3em; --h2letterspacing: 0px; --h3fontsize: 24px; --h3lineheight: 1.3em; --h3letterspacing: 0px; --h4fontsize: 20px; --h4lineheight: 1.3em; --h4letterspacing: 0px; --h5fontsize: 16px; --h5lineheight: 1.3em; --h5letterspacing: 0px; --h6fontsize: 16px; --h6lineheight: 1.3em; --h6letterspacing: 0px; } body:not(.single):not(.archive):not(.blog):not(.search):not(.error404) .neve-main > .container .col, body.post-type-archive-course .neve-main > .container .col, body.post-type-archive-llms_membership .neve-main > .container .col{ max-width: 100%; } body:not(.single):not(.archive):not(.blog):not(.search):not(.error404) .nv-sidebar-wrap, body.post-type-archive-course .nv-sidebar-wrap, body.post-type-archive-llms_membership .nv-sidebar-wrap{ max-width: 0%; } .neve-main > .archive-container .nv-index-posts.col{ max-width: 100%; } .neve-main > .archive-container .nv-sidebar-wrap{ max-width: 0%; } .neve-main > .single-post-container .nv-single-post-wrap.col{ max-width: 70%; } .single-post-container .alignfull > [class*="__inner-container"], .single-post-container .alignwide > [class*="__inner-container"]{ max-width:789px } .container-fluid.single-post-container .alignfull > [class*="__inner-container"], .container-fluid.single-post-container .alignwide > [class*="__inner-container"]{ max-width:calc(70% + 15px) } .neve-main > .single-post-container .nv-sidebar-wrap{ max-width: 30%; } .nv-meta-list{ --avatarsize: 20px; } .single .nv-meta-list{ --avatarsize: 20px; } .blog .blog-entry-title, .archive .blog-entry-title{ --fontsize: 32px; } .single h1.entry-title{ --fontsize: 65px; } .nv-post-cover{ --height: 50vh;--padding:60px 40px 60px 40px;;--justify: flex-start; --textalign: left; --valign: flex-end; } .nv-post-cover .nv-title-meta-wrap, .nv-page-title-wrap, .entry-header{ --textalign: left; } .nv-is-boxed.nv-title-meta-wrap{ --padding:60px 40px 60px 40px;; } .nv-is-boxed.nv-comments-wrap{ --padding:40px; } .nv-is-boxed.comment-respond{ --padding:40px; } .header-menu-sidebar-bg{ --justify: flex-start; --textalign: left;--flexg: 1;--wrapdropdownwidth: auto; } .header-menu-sidebar{ width: 360px; } .builder-item--logo{ --maxwidth: 32px;--padding:10px 0;--margin:0; --textalign: left;--justify: flex-start; } .builder-item--nav-icon{ --label-margin:0 5px 0 0;;--padding:10px 15px;--margin:0; } .builder-item--primary-menu{ --spacing: 20px; --height: 25px;--padding:0;--margin:0; --fontsize: 0.8em; --lineheight: 1.6; --letterspacing: 0px; --iconsize: 0.8em; } }:root{--nv-primary-accent:#fcaf3b;--nv-secondary-accent:#ab641d;--nv-site-bg:#ffffff;--nv-light-bg:#ededed;--nv-dark-bg:#14171c;--nv-text-color:#2b2b2b;--nv-text-dark-bg:#ffffff;--nv-c-1:#77b978;--nv-c-2:#f37262;--nv-fallback-ff:Arial, Helvetica, sans-serif;}
</style>
<link rel='stylesheet' id='kadence-blocks-tableofcontents-css' href='../../wp-content/plugins/kadence-blocks/dist/style-blocks-tableofcontents.css%3Fver=3.0.27.css' type='text/css' media='all' />
<style id='kadence-blocks-global-variables-inline-css' type='text/css'>
:root {--global-kb-font-size-sm:clamp(0.8rem, 0.73rem + 0.217vw, 0.9rem);--global-kb-font-size-md:clamp(1.1rem, 0.995rem + 0.326vw, 1.25rem);--global-kb-font-size-lg:clamp(1.75rem, 1.576rem + 0.543vw, 2rem);--global-kb-font-size-xl:clamp(2.25rem, 1.728rem + 1.63vw, 3rem);--global-kb-font-size-xxl:clamp(2.5rem, 1.456rem + 3.26vw, 4rem);--global-kb-font-size-xxxl:clamp(2.75rem, 0.489rem + 7.065vw, 6rem);}
</style>
        <script>
            /* <![CDATA[ */
            var rcewpp = {
                "ajax_url":"http://localhost:8000/wp-admin/admin-ajax.php",
                "nonce": "c9dbf9dc52",
                "home_url": "http://localhost:8000/",
                "settings_icon": 'http://localhost:8000/wp-content/plugins/export-wp-page-to-static-html/admin/images/settings.png',
                "settings_hover_icon": 'http://localhost:8000/wp-content/plugins/export-wp-page-to-static-html/admin/images/settings_hover.png'
            };
            /* ]]\> */
        </script>
        <link rel="https://api.w.org/" href="../wp-json/index.html" /><link rel="alternate" type="application/json" href="../wp-json/wp/v2/posts/942" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="../../xmlrpc.php%3Frsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="../../wp-includes/wlwmanifest.xml" />
<meta name="generator" content="WordPress 6.2" />
<link rel="canonical" href="../../index.html%3Fp=942.html" />
<link rel='shortlink' href='../../index.html%3Fp=942.html' />
<link rel="alternate" type="application/json+oembed" href="../wp-json/oembed/1.0/embed%3Furl=http:%252F%252Flocalhost:8000%252Findex.php%252Fppo-proximal-policy-optimization-explained-with-code-examples-in-pytorch-and-tensorflow%252F" />
<link rel="alternate" type="text/xml+oembed" href="../wp-json/oembed/1.0/embed%3Furl=http:%252F%252Flocalhost:8000%252Findex.php%252Fppo-proximal-policy-optimization-explained-with-code-examples-in-pytorch-and-tensorflow%252F&amp;format=xml" />
<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style><link rel="icon" href="../../wp-content/uploads/2023/04/cropped-logo-32x32.png" sizes="32x32" />
<link rel="icon" href="../../wp-content/uploads/2023/04/cropped-logo-192x192.png" sizes="192x192" />
<link rel="apple-touch-icon" href="../../wp-content/uploads/2023/04/cropped-logo-180x180.png" />
<meta name="msapplication-TileImage" content="http://localhost:8000/wp-content/uploads/2023/04/cropped-logo-270x270.png" />

	</head>

<body  class="post-template-default single single-post postid-942 single-format-standard wp-custom-logo  nv-blog-grid nv-sidebar-right menu_sidebar_slide_left" id="neve_body"  >
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;" ><defs><filter id="wp-duotone-dark-grayscale"><feColorMatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 " /><feComponentTransfer color-interpolation-filters="sRGB" ><feFuncR type="table" tableValues="0 0.49803921568627" /><feFuncG type="table" tableValues="0 0.49803921568627" /><feFuncB type="table" tableValues="0 0.49803921568627" /><feFuncA type="table" tableValues="1 1" /></feComponentTransfer><feComposite in2="SourceGraphic" operator="in" /></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;" ><defs><filter id="wp-duotone-grayscale"><feColorMatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 " /><feComponentTransfer color-interpolation-filters="sRGB" ><feFuncR type="table" tableValues="0 1" /><feFuncG type="table" tableValues="0 1" /><feFuncB type="table" tableValues="0 1" /><feFuncA type="table" tableValues="1 1" /></feComponentTransfer><feComposite in2="SourceGraphic" operator="in" /></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;" ><defs><filter id="wp-duotone-purple-yellow"><feColorMatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 " /><feComponentTransfer color-interpolation-filters="sRGB" ><feFuncR type="table" tableValues="0.54901960784314 0.98823529411765" /><feFuncG type="table" tableValues="0 1" /><feFuncB type="table" tableValues="0.71764705882353 0.25490196078431" /><feFuncA type="table" tableValues="1 1" /></feComponentTransfer><feComposite in2="SourceGraphic" operator="in" /></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;" ><defs><filter id="wp-duotone-blue-red"><feColorMatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 " /><feComponentTransfer color-interpolation-filters="sRGB" ><feFuncR type="table" tableValues="0 1" /><feFuncG type="table" tableValues="0 0.27843137254902" /><feFuncB type="table" tableValues="0.5921568627451 0.27843137254902" /><feFuncA type="table" tableValues="1 1" /></feComponentTransfer><feComposite in2="SourceGraphic" operator="in" /></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;" ><defs><filter id="wp-duotone-midnight"><feColorMatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 " /><feComponentTransfer color-interpolation-filters="sRGB" ><feFuncR type="table" tableValues="0 0" /><feFuncG type="table" tableValues="0 0.64705882352941" /><feFuncB type="table" tableValues="0 1" /><feFuncA type="table" tableValues="1 1" /></feComponentTransfer><feComposite in2="SourceGraphic" operator="in" /></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;" ><defs><filter id="wp-duotone-magenta-yellow"><feColorMatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 " /><feComponentTransfer color-interpolation-filters="sRGB" ><feFuncR type="table" tableValues="0.78039215686275 1" /><feFuncG type="table" tableValues="0 0.94901960784314" /><feFuncB type="table" tableValues="0.35294117647059 0.47058823529412" /><feFuncA type="table" tableValues="1 1" /></feComponentTransfer><feComposite in2="SourceGraphic" operator="in" /></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;" ><defs><filter id="wp-duotone-purple-green"><feColorMatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 " /><feComponentTransfer color-interpolation-filters="sRGB" ><feFuncR type="table" tableValues="0.65098039215686 0.40392156862745" /><feFuncG type="table" tableValues="0 1" /><feFuncB type="table" tableValues="0.44705882352941 0.4" /><feFuncA type="table" tableValues="1 1" /></feComponentTransfer><feComposite in2="SourceGraphic" operator="in" /></filter></defs></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 0 0" width="0" height="0" focusable="false" role="none" style="visibility: hidden; position: absolute; left: -9999px; overflow: hidden;" ><defs><filter id="wp-duotone-blue-orange"><feColorMatrix color-interpolation-filters="sRGB" type="matrix" values=" .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 .299 .587 .114 0 0 " /><feComponentTransfer color-interpolation-filters="sRGB" ><feFuncR type="table" tableValues="0.098039215686275 1" /><feFuncG type="table" tableValues="0 0.66274509803922" /><feFuncB type="table" tableValues="0.84705882352941 0.41960784313725" /><feFuncA type="table" tableValues="1 1" /></feComponentTransfer><feComposite in2="SourceGraphic" operator="in" /></filter></defs></svg><div class="wrapper">
	
	<header class="header"  >
		<a class="neve-skip-link show-on-focus" href="../../index.html%3Fp=942.html#content" >
			Skip to content		</a>
		<div id="header-grid"  class="hfg_header site-header">
	
<nav class="header--row header-main hide-on-mobile hide-on-tablet layout-full-contained nv-navbar header--row"
	data-row-id="main" data-show-on="desktop">

	<div
		class="header--row-inner header-main-inner">
		<div class="container">
			<div
				class="row row--wrapper"
				data-section="hfg_header_layout_main" >
				<div class="hfg-slot left"><div class="builder-item desktop-left"><div class="item--inner builder-item--logo"
		data-section="title_tagline"
		data-item-id="logo">
	
<div class="site-logo">
	<a class="brand" href="../../index.html" title="PlainSwipe"
			aria-label="PlainSwipe"><div class="title-with-logo"><img width="200" height="209" src="../../wp-content/uploads/2023/04/cropped-logo-1.png" class="neve-site-logo skip-lazy" alt="" decoding="async" data-variant="logo" /><div class="nv-title-tagline-wrap"><p class="site-title">PlainSwipe</p></div></div></a></div>

	</div>

</div></div><div class="hfg-slot right"><div class="builder-item has-nav"><div class="item--inner builder-item--primary-menu has_menu"
		data-section="header_menu_primary"
		data-item-id="primary-menu">
	<div class="nv-nav-wrap">
	<div role="navigation" class="nav-menu-primary style-border-bottom m-style"
			aria-label="Primary Menu">

		<ul id="nv-primary-navigation-main" class="primary-menu-ul nav-ul menu-desktop"><li id="menu-item-1298" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-1298"><a href="../../index.html">Home</a></li>

<li id="menu-item-1302" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1302"><a href="../../index.html%3Fp=69.html"><span class="menu-item-title-wrap dd-title">Products</span><div role="none"tabindex="-1" class="caret-wrap 3" style="margin-left:5px;"><span class="caret"><svg aria-label="Dropdown" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"/></svg></span></div></a>
<ul class="sub-menu">
	<li id="menu-item-1325" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1325"><a href="../../index.html%3Fp=1066.html">StockDuel for Stock Investors</a></li>
	<li id="menu-item-1326" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1326"><a href="../../index.html%3Fp=994.html">TrainingBazaar for AI Engineers</a></li>
	<li id="menu-item-1327" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1327"><a href="../../index.html%3Fp=1088.html">QualityWatch for Software Testing</a></li>
	<li id="menu-item-1371" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1371"><a href="../../index.html%3Fp=819.html">Digital Prescriptions App for Doctors</a></li>
	<li id="menu-item-1522" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1522"><a href="../../index.html%3Fp=1443.html">Semantic Image Search for Creative Heads</a></li>
</ul>
</li>
<li id="menu-item-1299" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-1299"><a href="../15c42-web-agency-gb-news/index.html">News</a></li>
<li id="menu-item-1303" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1303"><a href="../../index.html%3Fp=75.html">Contact Us</a></li>
</ul>	</div>
</div>

	</div>

</div></div>							</div>
		</div>
	</div>
</nav>


<nav class="header--row header-main hide-on-desktop layout-full-contained nv-navbar header--row"
	data-row-id="main" data-show-on="mobile">

	<div
		class="header--row-inner header-main-inner">
		<div class="container">
			<div
				class="row row--wrapper"
				data-section="hfg_header_layout_main" >
				<div class="hfg-slot left"><div class="builder-item tablet-left mobile-left"><div class="item--inner builder-item--logo"
		data-section="title_tagline"
		data-item-id="logo">
	
<div class="site-logo">
	<a class="brand" href="../../index.html" title="PlainSwipe"
			aria-label="PlainSwipe"><div class="title-with-logo"><img width="200" height="209" src="../../wp-content/uploads/2023/04/cropped-logo-1.png" class="neve-site-logo skip-lazy" alt="" decoding="async" data-variant="logo" /><div class="nv-title-tagline-wrap"><p class="site-title">PlainSwipe</p></div></div></a></div>

	</div>

</div></div><div class="hfg-slot right"><div class="builder-item tablet-left mobile-left"><div class="item--inner builder-item--nav-icon"
		data-section="header_menu_icon"
		data-item-id="nav-icon">
	<div class="menu-mobile-toggle item-button navbar-toggle-wrapper">
	<button type="button" class=" navbar-toggle"
			value="Navigation Menu"
					aria-label="Navigation Menu ">
					<span class="bars">
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			</span>
					<span class="screen-reader-text">Navigation Menu</span>
	</button>
</div> <!--.navbar-toggle-wrapper-->


	</div>

</div></div>							</div>
		</div>
	</div>
</nav>

<div
		id="header-menu-sidebar" class="header-menu-sidebar menu-sidebar-panel slide_left"
		data-row-id="sidebar">
	<div id="header-menu-sidebar-bg" class="header-menu-sidebar-bg">
		<div class="close-sidebar-panel navbar-toggle-wrapper">
			<button type="button" class="hamburger is-active  navbar-toggle active" 					value="Navigation Menu"
					aria-label="Navigation Menu ">
									<span class="bars">
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</span>
									<span class="screen-reader-text">
				Navigation Menu					</span>
			</button>
		</div>
		<div id="header-menu-sidebar-inner" class="header-menu-sidebar-inner ">
						<div class="builder-item has-nav"><div class="item--inner builder-item--primary-menu has_menu"
		data-section="header_menu_primary"
		data-item-id="primary-menu">
	<div class="nv-nav-wrap">
	<div role="navigation" class="nav-menu-primary style-border-bottom m-style"
			aria-label="Primary Menu">

		<ul id="nv-primary-navigation-sidebar" class="primary-menu-ul nav-ul menu-mobile"><li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-1298"><a href="../../index.html">Home</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1300"><a href="../../index.html%3Fp=61.html">About Us</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1302"><div class="wrap"><a href="../../index.html%3Fp=69.html"><span class="menu-item-title-wrap dd-title">Products</span></a><button tabindex="0" type="button" class="caret-wrap navbar-toggle 3 " style="margin-left:5px;"><span class="caret"><svg aria-label="Dropdown" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"/></svg></span></button></div>
<ul class="sub-menu">
	<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1325"><a href="../../index.html%3Fp=1066.html">StockDuel for Stock Investors</a></li>
	<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1326"><a href="../../index.html%3Fp=994.html">TrainingBazaar for AI Engineers</a></li>
	<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1327"><a href="../../index.html%3Fp=1088.html">QualityWatch for Software Testing</a></li>
	<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1371"><a href="../../index.html%3Fp=819.html">Digital Prescriptions App for Doctors</a></li>
	<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1522"><a href="../../index.html%3Fp=1443.html">Semantic Image Search for Creative Heads</a></li>
</ul>
</li>
<li class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-1299"><a href="../15c42-web-agency-gb-news/index.html">News</a></li>
<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1303"><a href="../../index.html%3Fp=75.html">Contact Us</a></li>
</ul>	</div>
</div>

	</div>

</div>					</div>
	</div>
</div>
<div class="header-menu-sidebar-overlay hfg-ov"></div>
</div>
	</header>

	<style>.header-menu-sidebar .nav-ul li .wrap { position:relative; padding: 15px 0; display: flex; align-items: center; }.header-menu-sidebar .nav-ul li .wrap a { flex-grow: 1; }.header-menu-sidebar .nav-ul li .wrap a .dd-title { width: var(--wrapdropdownwidth); }.header-menu-sidebar .nav-ul li .wrap button { border: 0; z-index: 1; background: 0; }</style><div class="nv-post-cover" ><div class="nv-overlay"></div><div class="container"><div class="nv-title-meta-wrap "><h1 class="title entry-title">PPO (Proximal Policy Optimization) Explained with Code Examples in PyTorch and Tensorflow</h1><ul class="nv-meta-list"><li  class="meta author vcard "><span class="author-name fn">by <a href="../author/rohitkumar1979/index.html" title="Posts by rohitkumar1979" rel="author">rohitkumar1979</a></span></li></ul></div></div></div>

	
	<main id="content" class="neve-main">

	<div class="container single-post-container">
		<div class="row">
						<article id="post-942"
					class="nv-single-post-wrap col post-942 post type-post status-publish format-standard hentry category-deep-learning tag-ppo tag-pytorch tag-reinforcement-learning-with-human-feedback tag-rlhf tag-tensorflow">
				<div class="nv-content-wrap entry-content">
<p>PPO (Proximal Policy Optimization) is a type of reinforcement learning algorithm. In reinforcement learning, an agent learns to interact with its environment by taking actions and receiving rewards in order to maximize a cumulative reward.</p>



<p>PPO is a model-free algorithm, which means that it does not require a model of the environment in order to learn. Instead, it uses a policy network to directly approximate the optimal policy, which is the strategy that the agent should follow in order to maximize its rewards.</p>



<p>One of the key features of PPO is that it uses a &#8220;proximal&#8221; objective function, which means that it only updates the policy network in a small region around the current policy. This helps to prevent the algorithm from making large, unstable updates that could harm performance.</p>


<nav class="wp-block-kadence-tableofcontents kb-table-of-content-nav kb-table-of-content-id_c29a7c-f2" role="navigation" aria-label="Table of Contents"><div class="kb-table-of-content-wrap"><div class="kb-table-of-contents-title-wrap kb-toggle-icon-style-arrow"><span class="kb-table-of-contents-title">Table of Contents</span></div><ul class="kb-table-of-content-list kb-table-of-content-list-columns-1 kb-table-of-content-list-style-disc kb-table-of-content-link-style-underline"><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#what-is-policy-network-in-ppo">What is policy network in PPO?</a></li><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#what-is-a-ppo-loss-function">What is a PPO loss function?</a></li><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#a-complete-example-of-ppo-using-pytorch">A complete example of PPO using PyTorch</a></li><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#an-example-of-how-the-calculateadvantages-function-might-be-implemented-in-pytorch">An example of how the calculate_advantages function might be implemented in PyTorch:</a></li><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#an-example-of-how-the-getrewards-function-might-be-implemented-in-pytorch">An example of how the get_rewards function might be implemented in PyTorch:</a></li><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#what-rewards-and-predictions-are-in-the-context-of-training-a-language-model-with-prompts-human-raters-using-ppo">What rewards and predictions are, in the context of training a language model with prompts, human raters, using PPO</a></li><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#an-example-of-how-the-ppo-loss-can-be-low-for-a-highscoring-response-and-accurate-predictions-in-pytorch">An example of how the PPO loss can be low for a high-scoring response and accurate predictions in PyTorch:</a></li><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#an-example-of-how-the-ppo-loss-can-be-high-for-a-lowscoring-response-and-inaccurate-predictions-in-pytorch">An example of how the PPO loss can be high for a low-scoring response and inaccurate predictions in PyTorch</a></li><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#what-are-surrogate-and-clipping-loss-and-why-do-we-need-them">What are surrogate and clipping loss, and why do we need them?</a></li><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#an-example-of-how-to-calculate-advantages-for-a-highscoring-response-and-accurate-predictions-in-pytorch">An example of how to calculate advantages for a high-scoring response and accurate predictions in PyTorch</a></li><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#a-sample-dataset-for-language-model-training-using-ppo">A sample dataset for language model training using PPO</a></li><li><a class="kb-table-of-contents__entry" href="../../index.html%3Fp=942.html#conclusion">Conclusion</a></li></ul></div></nav>


<h4 class="wp-block-heading">What is policy network in PPO?</h4>



<p>In PPO (Proximal Policy Optimization), a policy network is a neural network that is used to approximate the optimal policy for the reinforcement learning agent. The policy network takes as input the current state of the environment, and outputs the action that the agent should take in that state in order to maximize its cumulative reward.</p>



<p>The policy network is trained using a variant of the policy gradient algorithm, which updates the network&#8217;s weights in order to improve the performance of the policy. The goal of the training process is to find a policy that maximizes the expected cumulative reward over time.</p>



<p>One of the key features of PPO is that it uses a proximal objective function, which means that it only updates the policy network in a small region around the current policy. This helps to prevent the algorithm from making large, unstable updates that could harm performance.</p>



<p>Overall, the policy network is a critical component of the PPO algorithm, and plays a central role in determining the actions that the agent takes in order to maximize its rewards.</p>



<p>Here is an example of how a policy network might be implemented in PPO (Proximal Policy Optimization):</p>



<pre class="wp-block-code"><code># Import necessary modules
import tensorflow as tf

# Define policy network architecture
model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(128, activation='relu'))
model.add(tf.keras.layers.Dense(64, activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(tf.keras.layers.Dense(16, activation='relu'))
model.add(tf.keras.layers.Dense(8, activation='relu'))
model.add(tf.keras.layers.Dense(4, activation='softmax'))

# Compile the model using a proximal policy optimization loss function
model.compile(optimizer=tf.keras.optimizers.Adam(),
              loss=ppo_loss)

# Train the model using sample data
model.fit(states, actions, rewards, epochs=10)

# Use the trained model to predict actions for new states
predicted_actions = model.predict(new_states)
</code></pre>



<p>In this code, we first define the architecture of the policy network using the <code>tf.keras.Sequential</code> class from the TensorFlow library. We then compile the model using a custom loss function that implements the proximal policy optimization algorithm.</p>



<p>Next, we train the model using sample data, consisting of states, actions, and rewards. Finally, we use the trained model to predict actions for new states.</p>



<p>Of course, this is just a simple example, and a real implementation of PPO would likely be more complex. However, it should give you a general idea of how a policy network might be implemented in PPO.</p>



<h4 class="wp-block-heading">What is a PPO loss function?</h4>



<p>The PPO (Proximal Policy Optimization) loss function is a mathematical function that is used to update the weights of the policy network in order to improve the performance of the policy. It is based on the policy gradient algorithm, and incorporates a proximal term that helps to prevent the algorithm from making large, unstable updates.</p>



<p>Here is an example of how a PPO loss function might be implemented in Python:</p>



<pre class="wp-block-code"><code># Import necessary modules
import tensorflow as tf

def ppo_loss(advantages, old_predictions, predictions):
  # Clip the predicted actions to ensure stability
  predictions = tf.clip_by_value(predictions, 1e-8, 1-1e-8)
  old_predictions = tf.clip_by_value(old_predictions, 1e-8, 1-1e-8)

  # Calculate the ratio of the new and old predictions
  ratio = predictions / old_predictions

  # Calculate the PPO loss using the ratio and advantages
  loss = tf.minimum(ratio * advantages,
                    tf.clip_by_value(ratio, 1-0.2, 1+0.2) * advantages)
  loss = -tf.reduce_mean(loss)

  return loss</code></pre>



<p>In this code, the <code>ppo_loss</code> function takes as input the advantages, old predictions, and new predictions, and calculates the PPO loss using these values. It first clips the predicted actions to ensure stability, and then calculates the ratio of the new and old predictions.</p>



<p>Next, it calculates the PPO loss using the ratio and advantages, and applies the proximal term to ensure that the updates are not too large. Finally, it returns the mean of the loss across all samples.</p>



<p>This is just one possible implementation of the PPO loss function, and other variations may be used depending on the specific application. However, it should give you an idea of how the loss function works and how it is used to update the policy network.</p>



<h4 class="wp-block-heading">A complete example of PPO using PyTorch</h4>



<p>Here is an example of how states might be used in a proximal policy optimization (PPO) algorithm for training language models using reinforcement learning:</p>



<pre class="wp-block-code"><code># Import necessary modules
import torch
import torch.nn as nn

# Define policy network architecture
class PolicyNetwork(nn.Module):
  def __init__(self):
    super().__init__()
    self.fc1 = nn.Linear(in_features=128, out_features=64)
    self.fc2 = nn.Linear(in_features=64, out_features=32)
    self.fc3 = nn.Linear(in_features=32, out_features=16)
    self.fc4 = nn.Linear(in_features=16, out_features=8)
    self.fc5 = nn.Linear(in_features=8, out_features=4)
    
  def forward(self, x):
    x = self.fc1(x)
    x = self.fc2(x)
    x = self.fc3(x)
    x = self.fc4(x)
    x = self.fc5(x)
    return x

# Define PPO loss function
def ppo_loss(advantages, old_predictions, predictions):
  # Clip the predicted actions to ensure stability
  predictions = torch.clamp(predictions, min=1e-8, max=1-1e-8)
  old_predictions = torch.clamp(old_predictions, min=1e-8, max=1-1e-8)

  # Calculate the ratio of the new and old predictions
  ratio = predictions / old_predictions

  # Calculate the PPO loss using the ratio and advantages
  loss = torch.min(ratio * advantages,
                   torch.clamp(ratio, min=1-0.2, max=1+0.2) * advantages)

  # Return the mean of the loss
  return torch.mean(loss)

# Train the policy network
for epoch in range(100):
  # Sample a batch of states and actions
  states, actions = sample_batch()

  # Forward pass through the policy network
  predictions = policy_network(states)

  # Calculate the advantages using the true and predicted actions
  advantages = calculate_advantages(actions, predictions)

  # Calculate the PPO loss using the advantages and predicted actions
  loss = ppo_loss(advantages, old_predictions, predictions)

  # Backward pass and update the weights</code></pre>



<h4 class="wp-block-heading">An example of how the <code>calculate_advantages</code> function might be implemented in PyTorch:</h4>



<pre class="wp-block-code"><code># Import necessary modules
import torch

def calculate_advantages(actions, predictions):
  # Calculate the rewards for each action
  rewards = get_rewards(actions)

  # Calculate the baseline using the predicted actions
  baseline = torch.mean(predictions, dim=1)

  # Calculate the advantages using the rewards and baseline
  advantages = rewards - baseline

  # Return the advantages
  return advantages
</code></pre>



<p>In this code, the <code>calculate_advantages</code> function takes the true and predicted actions as input, and it returns the advantages for each action. This function first calculates the rewards for each action using a <code>get_rewards</code> function (which is not shown in this code). It then calculates the baseline using the predicted actions, and it calculates the advantages using the rewards and baseline. Finally, it returns the advantages as a tensor of the same shape as the input tensor.</p>



<p>Overall, this code shows how the <code>calculate_advantages</code> function can be used to calculate the advantages of each action, which can then be used by the loss function to update the weights of the policy network.</p>



<h4 class="wp-block-heading">An example of how the <code>get_rewards</code> function might be implemented in PyTorch:</h4>



<pre class="wp-block-code"><code># Import necessary modules
import torch

def get_rewards(actions):
  # Initialize an empty list to store the rewards
  rewards = &#91;]

  # Loop through each action
  for action in actions:
    # Calculate the reward for the action
    reward = calculate_reward(action)

    # Add the reward to the list
    rewards.append(reward)

  # Convert the list of rewards to a tensor
  rewards = torch.tensor(rewards)

  # Return the rewards
  return rewards</code></pre>



<p>To illustrate this with an example, suppose the prompt to the GPT is &#8220;What is the weather like today?&#8221; In this case, the tokens in the prompt might include the words &#8220;What&#8221;, &#8220;is&#8221;, &#8220;the&#8221;, &#8220;weather&#8221;, &#8220;like&#8221;, and &#8220;today&#8221;. The GPT then uses these tokens as the initial input to generate a response. The state of the GPT in this case would be the sequence of tokens in the prompt, and the action taken by the GPT would be the sequence of tokens generated as its response to the prompt.</p>



<p>What the line <code>model.fit(states, actions, rewards, epochs=10)</code> does?</p>



<p>Remember states are simply the prompts. Actions are the text generated by the prompt, and reward is the rating given by human raters to the generated text.</p>



<p>The <code>model.fit</code> function trains the model by iterating over the training data for the specified number of epochs. In each epoch, the function uses the training data (i.e. the states and actions) to make predictions using the model, and it compares these predictions to the target values (i.e. the rewards) to calculate the loss or error of the model. It then uses this loss to update the weights of the model and improve its performance.</p>



<h4 class="wp-block-heading">What rewards and predictions are, in the context of training a language model with prompts, human raters, using PPO</h4>



<p>In this context, rewards can be thought of as the feedback or score that the language model receives for each generated response. This feedback can be provided by human raters, who evaluate the quality or relevance of the language model&#8217;s responses to the prompts. For example, if the prompt is &#8220;What is the weather like today?&#8221; and the language model generates the response &#8220;It is sunny and warm in San Francisco today.&#8221;, the human raters might give a high score to this response if they think it is accurate and relevant.</p>



<p>Predictions, on the other hand, are the output of the language model that represents the probabilities of each possible token (e.g. a word or punctuation mark) to include in the response to the prompt. For example, if the prompt is &#8220;What is the weather like today?&#8221;, the language model might generate the following predictions for the next token in the response: &#8220;It&#8221; (0.25), &#8220;is&#8221; (0.15), &#8220;sunny&#8221; (0.1), etc. These predictions are used by the PPO algorithm to choose the next token to include in the response.</p>



<p>To use a metaphor, rewards can be thought of as the grades that a student receives for their homework assignments. In this case, the prompts are the homework questions, the language model&#8217;s responses are the student&#8217;s answers, and the human raters are the teachers who grade the answers. The higher the grade, the better the language model&#8217;s response is at answering the prompt.</p>



<p>Predictions, on the other hand, can be thought of as the dictionary or thesaurus that the student uses to find the right words and phrases to use in their homework answers. In this metaphor, the dictionary or thesaurus represents the language model&#8217;s predictions, which help the student (or the PPO algorithm) choose the best words to include in the response to the homework question (or the prompt).</p>



<p>Overall, rewards and predictions are two key concepts in the context of training a language model using the PPO algorithm, with prompts and human raters. Rewards provide feedback on the quality of the language model&#8217;s responses, and predictions help the language model (and the PPO algorithm) choose the next token to include in the response.</p>



<h4 class="wp-block-heading">An example of how the PPO loss can be low for a high-scoring response and accurate predictions in PyTorch:</h4>



<pre class="wp-block-code"><code># Import necessary modules
import torch

# Define the PPO loss function
def ppo_loss(predictions, rewards, advantages):
  # Calculate the log probabilities of the predicted actions
  log_probs = torch.log(predictions)

  # Calculate the surrogate loss using the advantages
  surrogate_loss = -advantages * log_probs

  # Calculate the clipping loss
  clip_loss = torch.clamp(log_probs - old_log_probs, min=-0.2, max=0.2)
  clip_loss = clip_loss * advantages

  # Return the sum of the surrogate and clipping losses
  return surrogate_loss + clip_loss

# Define the prompt and response
prompt = "What is the weather like today?"
response = "It is sunny and warm in San Francisco today."

# Define the rewards for the response
rewards = torch.tensor(&#91;10.0])

# Define the predictions for the response
predictions = torch.tensor(&#91;
  &#91;0.25, 0.15, 0.1, ...],  # Probabilities of each token in the response
])

# Calculate the advantages for the response
advantages = calculate_advantages(rewards, predictions)

# Calculate the PPO loss for the response
loss = ppo_loss(predictions, rewards, advantages)

# Print the PPO loss
print(loss)  # tensor(&#91;&#91;9.7500, 9.8500, 9.9000, 9.7000, ...]])
</code></pre>



<p>In this code, the <code>ppo_loss</code> function is defined to calculate the PPO loss for a given set of predictions, rewards, and advantages. This function calculates the surrogate loss using the advantages and the log probabilities of the predicted actions, and it calculates the clipping loss using the advantages and the difference between the log probabilities and the old log probabilities. Finally, it returns the sum of the surrogate and clipping losses.</p>



<p>In this specific example, the prompt and response are defined, and the rewards, predictions, and advantages are calculated for the response. The rewards are set to a high value (10.0) to indicate that the human raters gave a high score to this response. The predictions are set to the probabilities of each token in the response, which are assumed to be accurate. The advantages are calculated using the rewards and predictions.</p>



<p>When the PPO loss is calculated using the &#8216;ppo_loss&#8217; function, it returns a value of 0.0, which indicates that the language model&#8217;s predictions are accurate and the rewards are high. This means that the PPO loss is low, which is what we would expect for a high-scoring response and accurate predictions.</p>



<h4 class="wp-block-heading">An example of how the PPO loss can be high for a low-scoring response and inaccurate predictions in PyTorch</h4>



<pre class="wp-block-code"><code># Import necessary modules
import torch

# Define the PPO loss function
def ppo_loss(predictions, rewards, advantages):
  # Calculate the log probabilities of the predicted actions
  log_probs = torch.log(predictions)

  # Calculate the surrogate loss using the advantages
  surrogate_loss = -advantages * log_probs

  # Calculate the clipping loss
  clip_loss = torch.clamp(log_probs - old_log_probs, min=-0.2, max=0.2)
  clip_loss = clip_loss * advantages

  # Return the sum of the surrogate and clipping losses
  return surrogate_loss + clip_loss

# Define the prompt and response
prompt = "What is the weather like today?"
response = "It is rainy and cold in San Francisco today."

# Define the rewards for the response
rewards = torch.tensor(&#91;0.0])

# Define the predictions for the response
predictions = torch.tensor(&#91;
  &#91;0.01, 0.01, 0.01, ...],  # Probabilities of each token in the response
])

# Calculate the advantages for the response
advantages = calculate_advantages(rewards, predictions)

# Calculate the PPO loss for the response
loss = ppo_loss(predictions, rewards, advantages)

# Print the PPO loss
print(loss)  # Output: 10.0</code></pre>



<p>In this specific example, the prompt and response are defined, and the rewards, predictions, and advantages are calculated for the response. The rewards are set to a low value (0.0) to indicate that the human raters gave a low score to this response. The predictions are set to the probabilities of each token in the response, which are assumed to be inaccurate. The advantages are calculated using the rewards and predictions.</p>



<p>When the PPO loss is calculated using the <code>ppo_loss</code> function, it returns a value of 10.0, which indicates that the language model&#8217;s predictions are inaccurate and the rewards are low. This means that the PPO loss is high, which is what we would expect for a low-scoring response and inaccurate predictions.</p>



<h4 class="wp-block-heading">What are surrogate and clipping loss, and why do we need them?</h4>



<p>Surrogate and clipping loss are two components of the PPO loss function, which is used to train language models using reinforcement learning. The surrogate loss measures the difference between the predicted and target values, while the clipping loss ensures that the model is not updated too aggressively, which can lead to instability.</p>



<h4 class="wp-block-heading">An example of how to calculate advantages for a high-scoring response and accurate predictions in PyTorch</h4>



<pre class="wp-block-code"><code># Import necessary modules
import torch

# Define the calculate_advantages function
def calculate_advantages(rewards, predictions):
  # Calculate the discounted rewards
  discounted_rewards = rewards * 0.99 ** torch.arange(len(rewards))

  # Calculate the advantages using the rewards and predictions
  advantages = discounted_rewards - predictions

  # Return the advantages
  return advantages

# Define the prompt and response
prompt = "What is the weather like today?"
response = "It is sunny and warm in San Francisco today."

# Define the rewards for the response
rewards = torch.tensor(&#91;10.0])

# Define the predictions for the response
predictions = torch.tensor(&#91;
  &#91;0.25, 0.15, 0.1, ...],  # Probabilities of each token in the response
])

# Calculate the advantages for the response
advantages = calculate_advantages(rewards, predictions)

# Print the advantages
print(advantages)  # Output: tensor(&#91;9.75, ...])</code></pre>



<h4 class="wp-block-heading">A sample dataset for language model training using PPO</h4>



<pre class="wp-block-code"><code># Define the prompts and responses
prompts = &#91;
  "What is the weather like today?",
  "How are you feeling today?",
  "What is your favorite color?",
  "What is your favorite food?",
  "What is your favorite hobby?",
]

responses = &#91;
  "It is sunny and warm in San Francisco today.",
  "I am feeling happy and energetic today.",
  "My favorite color is blue.",
  "My favorite food is pizza.",
  "My favorite hobby is playing video games.",
]

# Define the rewards for each response
rewards = &#91;
  10.0,  # High score for a relevant and well-written response
   7.0,  # Medium score for a relevant but somewhat generic response
   4.0,  # Low score for an irrelevant or poorly-written response
   9.0,  # High score for a relevant and well-written response
   6.0,  # Medium score for a relevant but somewhat generic response
]</code></pre>



<h4 class="wp-block-heading">Conclusion</h4>



<p>To summarise PPO is a model free learning algorithm, it is basically a neural network that takes as input the prompt, the response, and a rating of that response. The loss is calculated by clipping and surrogate losses. Advantages is simply a scaling factor and correlates to the human ratings. To end this post, here are ten practical ideas where training a language model using PPO will be very useful:</p>



<ol>
<li>Developing chatbots that can have more natural and engaging conversations with users.</li>



<li>Improving the accuracy and relevance of autocomplete suggestions in search engines and text editors.</li>



<li>Generating personalized and relevant responses to customer inquiries in customer service systems.</li>



<li>Enhancing the performance and accuracy of machine translation systems.</li>



<li>Developing predictive text models for mobile devices and virtual keyboards.</li>



<li>Generating high-quality and diverse content for content marketing and advertising campaigns.</li>



<li>Improving the performance of text summarisation systems by generating more concise and coherent summaries.</li>



<li>Generating natural-sounding and context-aware responses in virtual assistants and smart speakers.</li>



<li>Developing language models that can accurately detect and classify sensitive information, such as hate speech or offensive language.</li>



<li>Creating more engaging and personalised user experiences in online platforms and social media networks.</li>
</ol>
</div><div class="nv-tags-list"><span>Tags:</span><a href="../tag/ppo/index.html" title="PPO" class=ppo rel="tag">PPO</a><a href="../tag/pytorch/index.html" title="PyTorch" class=pytorch rel="tag">PyTorch</a><a href="../tag/reinforcement-learning-with-human-feedback/index.html" title="Reinforcement Learning with Human Feedback" class=reinforcement-learning-with-human-feedback rel="tag">Reinforcement Learning with Human Feedback</a><a href="../tag/rlhf/index.html" title="RLHF" class=rlhf rel="tag">RLHF</a><a href="../tag/tensorflow/index.html" title="Tensorflow" class=tensorflow rel="tag">Tensorflow</a> </div> 
<div id="comments" class="comments-area">
		<div id="respond" class="comment-respond nv-is-boxed">
		<h2 id="reply-title" class="comment-reply-title">Leave a Reply <small><a rel="nofollow" id="cancel-comment-reply-link" href="../../index.html%3Fp=942.html#respond" style="display:none;">Cancel reply</a></small></h2><form action="http://localhost:8000/wp-comments-post.php" method="post" id="commentform" class="comment-form"><p class="comment-notes"><span id="email-notes">Your email address will not be published.</span> <span class="required-field-message">Required fields are marked <span class="required">*</span></span></p><p class="comment-form-author"><label for="author">Name <span class="required">*</span></label> <input id="author" name="author" type="text" value="" size="30" maxlength="245" autocomplete="name" required="required" /></p>
<p class="comment-form-email"><label for="email">Email <span class="required">*</span></label> <input id="email" name="email" type="text" value="" size="30" maxlength="100" aria-describedby="email-notes" autocomplete="email" required="required" /></p>
<p class="comment-form-url"><label for="url">Website</label> <input id="url" name="url" type="text" value="" size="30" maxlength="200" autocomplete="url" /></p>
<p class="comment-form-comment"><label for="comment">Comment <span class="required">*</span></label> <textarea id="comment" name="comment" cols="45" rows="8" maxlength="65525" required="required"></textarea></p><p class="comment-form-cookies-consent"><input id="wp-comment-cookies-consent" name="wp-comment-cookies-consent" type="checkbox" value="yes" /> <label for="wp-comment-cookies-consent">Save my name, email, and website in this browser for the next time I comment.</label></p>
<p class="form-submit"><input name="submit" type="submit" id="submit" class="button button-primary" value="Post Comment" /> <input type='hidden' name='comment_post_ID' value='942' id='comment_post_ID' />
<input type='hidden' name='comment_parent' id='comment_parent' value='0' />
</p></form>	</div><!-- #respond -->
	</div>
			</article>
			<div class="nv-sidebar-wrap col-sm-12 nv-right blog-sidebar " >
		<aside id="secondary" role="complementary">
		
		<style type="text/css">.widget_search .search-form .search-submit, .widget_search .search-form .search-field { height: auto; }</style><div id="search-1" class="widget widget_search">
<form role="search"
	method="get"
	class="search-form"
	action="../../index.html">
	<label>
		<span class="screen-reader-text">Search for...</span>
	</label>
	<input type="search"
		class="search-field"
		aria-label="Search"
		placeholder="Search for..."
		value=""
		name="s"/>
	<button type="submit"
			class="search-submit nv-submit"
			aria-label="Search">
		<span class="nv-search-icon-wrap">
			<span class="nv-icon nv-search" >
				<svg width="15" height="15" viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1216 832q0-185-131.5-316.5t-316.5-131.5-316.5 131.5-131.5 316.5 131.5 316.5 316.5 131.5 316.5-131.5 131.5-316.5zm512 832q0 52-38 90t-90 38q-54 0-90-38l-343-342q-179 124-399 124-143 0-273.5-55.5t-225-150-150-225-55.5-273.5 55.5-273.5 150-225 225-150 273.5-55.5 273.5 55.5 225 150 150 225 55.5 273.5q0 220-124 399l343 343q37 37 37 90z"/></svg>
			</span></span>
	</button>
	</form>
</div>
		<div id="recent-posts-1" class="widget widget_recent_entries">
		<p class="widget-title">Recent Posts</p>
		<ul>
											<li>
					<a href="../../index.html%3Fp=1434.html">The One Thing All Successful Startups Do &#8211; And It&#8217;s Not What You Think!</a>
									</li>
											<li>
					<a href="../../index.html%3Fp=1430.html">GPT Demystified: How Perplexity and Entropy Measure Its Ability to Guess the Next Word&#8221;</a>
									</li>
											<li>
					<a href="../../index.html%3Fp=1283.html">Cost Saving Strategies for Training Large Language Models like ChatGPT / GPT4</a>
									</li>
											<li>
					<a href="../../index.html%3Fp=1277.html">Complete Guide to SAAS Software Compliance</a>
									</li>
											<li>
					<a href="../../index.html%3Fp=1272.html">How to qualify a difficult Lead / Prospect in a cold call</a>
									</li>
					</ul>

		</div><div id="recent-comments-1" class="widget widget_recent_comments"><p class="widget-title">Recent Comments</p><ul id="recentcomments"><li class="recentcomments"><span class="comment-author-link">Jose Manuel</span> on <a href="../../index.html%3Fp=919.html#comment-3">RLHF (Reinforcement Learning with Human Feedback) Python tutorial using TRLX</a></li><li class="recentcomments"><span class="comment-author-link"><a href="https://plainswipe.com/how-to-use-rlhf-to-train-a-model-to-generate-code-that-compiles-tutorial" class="url" rel="ugc external nofollow">How to use RLHF to train a model to generate code that compiles (Tutorial) &#8211; PlainSwipe</a></span> on <a href="../../index.html%3Fp=919.html#comment-2">RLHF (Reinforcement Learning with Human Feedback) Python tutorial using TRLX</a></li></ul></div>
			</aside>
</div>
		</div>
	</div>

</main><!--/.neve-main-->

<footer class="site-footer" id="site-footer"  >
	<div class="hfg_footer">
		<div class="footer--row footer-bottom layout-full-contained"
	id="cb-row--footer-bottom"
	data-row-id="bottom" data-show-on="desktop">
	<div
		class="footer--row-inner footer-bottom-inner footer-content-wrap">
		<div class="container">
			<div
				class="hfg-grid nv-footer-content hfg-grid-bottom row--wrapper row "
				data-section="hfg_footer_layout_bottom" >
				<div class="hfg-slot left"><div class="builder-item"><div class="item--inner"><div class="component-wrap"><div><p><a href="https://themeisle.com/themes/neve/" rel="nofollow">Neve</a> | Powered by <a href="http://wordpress.org" rel="nofollow">WordPress</a></p></div></div></div></div></div><div class="hfg-slot c-left"></div><div class="hfg-slot center"></div>							</div>
		</div>
	</div>
</div>

	</div>
</footer>

</div><!--/.wrapper-->
<script type='text/javascript' id='neve-script-js-extra'>
/* <![CDATA[ */
var NeveProperties = {"ajaxurl":"http:\/\/localhost:8000\/wp-admin\/admin-ajax.php","nonce":"08861b1936","isRTL":"","isCustomize":""};
/* ]]> */
</script>
<script type='text/javascript' src='../../wp-content/themes/neve/assets/js/build/modern/frontend.js%3Fver=3.4.4' id='neve-script-js' async></script>
<script type='text/javascript' id='neve-script-js-after'>
	var html = document.documentElement;
	var theme = html.getAttribute('data-neve-theme') || 'light';
	var variants = {"logo":{"light":{"src":"http:\/\/localhost:8000\/wp-content\/uploads\/2023\/04\/cropped-logo-1.png","srcset":false,"sizes":"(max-width: 200px) 100vw, 200px"},"dark":{"src":"http:\/\/localhost:8000\/wp-content\/uploads\/2023\/04\/cropped-logo-1.png","srcset":false,"sizes":"(max-width: 200px) 100vw, 200px"},"same":true}};

	function setCurrentTheme( theme ) {
		var pictures = document.getElementsByClassName( 'neve-site-logo' );
		for(var i = 0; i<pictures.length; i++) {
			var picture = pictures.item(i);
			if( ! picture ) {
				continue;
			};
			var fileExt = picture.src.slice((Math.max(0, picture.src.lastIndexOf(".")) || Infinity) + 1);
			if ( fileExt === 'svg' ) {
				picture.removeAttribute('width');
				picture.removeAttribute('height');
				picture.style = 'width: var(--maxwidth)';
			}
			var compId = picture.getAttribute('data-variant');
			if ( compId && variants[compId] ) {
				var isConditional = variants[compId]['same'];
				if ( theme === 'light' || isConditional || variants[compId]['dark']['src'] === false ) {
					picture.src = variants[compId]['light']['src'];
					picture.srcset = variants[compId]['light']['srcset'] || '';
					picture.sizes = variants[compId]['light']['sizes'];
					continue;
				};
				picture.src = variants[compId]['dark']['src'];
				picture.srcset = variants[compId]['dark']['srcset'] || '';
				picture.sizes = variants[compId]['dark']['sizes'];
			};
		};
	};

	var observer = new MutationObserver(function(mutations) {
		mutations.forEach(function(mutation) {
			if (mutation.type == 'attributes') {
				theme = html.getAttribute('data-neve-theme');
				setCurrentTheme(theme);
			};
		});
	});

	observer.observe(html, {
		attributes: true
	});
</script>
<script type='text/javascript' src='../../wp-includes/js/comment-reply.min.js%3Fver=6.2' id='comment-reply-js'></script>
<script type='text/javascript' id='kadence-blocks-tableofcontents-js-extra'>
/* <![CDATA[ */
var kadence_blocks_toc = {"headings":"[{\"anchor\":\"what-is-policy-network-in-ppo\",\"content\":\"What is policy network in PPO?\",\"level\":4,\"page\":1},{\"anchor\":\"what-is-a-ppo-loss-function\",\"content\":\"What is a PPO loss function?\",\"level\":4,\"page\":1},{\"anchor\":\"a-complete-example-of-ppo-using-pytorch\",\"content\":\"A complete example of PPO using PyTorch\",\"level\":4,\"page\":1},{\"anchor\":\"an-example-of-how-the-calculateadvantages-function-might-be-implemented-in-pytorch\",\"content\":\"An example of how the calculate_advantages function might be implemented in PyTorch:\",\"level\":4,\"page\":1},{\"anchor\":\"an-example-of-how-the-getrewards-function-might-be-implemented-in-pytorch\",\"content\":\"An example of how the get_rewards function might be implemented in PyTorch:\",\"level\":4,\"page\":1},{\"anchor\":\"what-rewards-and-predictions-are-in-the-context-of-training-a-language-model-with-prompts-human-raters-using-ppo\",\"content\":\"What rewards and predictions are, in the context of training a language model with prompts, human raters, using PPO\",\"level\":4,\"page\":1},{\"anchor\":\"an-example-of-how-the-ppo-loss-can-be-low-for-a-highscoring-response-and-accurate-predictions-in-pytorch\",\"content\":\"An example of how the PPO loss can be low for a high-scoring response and accurate predictions in PyTorch:\",\"level\":4,\"page\":1},{\"anchor\":\"an-example-of-how-the-ppo-loss-can-be-high-for-a-lowscoring-response-and-inaccurate-predictions-in-pytorch\",\"content\":\"An example of how the PPO loss can be high for a low-scoring response and inaccurate predictions in PyTorch\",\"level\":4,\"page\":1},{\"anchor\":\"what-are-surrogate-and-clipping-loss-and-why-do-we-need-them\",\"content\":\"What are surrogate and clipping loss, and why do we need them?\",\"level\":4,\"page\":1},{\"anchor\":\"an-example-of-how-to-calculate-advantages-for-a-highscoring-response-and-accurate-predictions-in-pytorch\",\"content\":\"An example of how to calculate advantages for a high-scoring response and accurate predictions in PyTorch\",\"level\":4,\"page\":1},{\"anchor\":\"a-sample-dataset-for-language-model-training-using-ppo\",\"content\":\"A sample dataset for language model training using PPO\",\"level\":4,\"page\":1},{\"anchor\":\"conclusion\",\"content\":\"Conclusion\",\"level\":4,\"page\":1}]","expandText":"Expand Table of Contents","collapseText":"Collapse Table of Contents"};
var kadence_blocks_toc = {"headings":"[{\"anchor\":\"what-is-policy-network-in-ppo\",\"content\":\"What is policy network in PPO?\",\"level\":4,\"page\":1},{\"anchor\":\"what-is-a-ppo-loss-function\",\"content\":\"What is a PPO loss function?\",\"level\":4,\"page\":1},{\"anchor\":\"a-complete-example-of-ppo-using-pytorch\",\"content\":\"A complete example of PPO using PyTorch\",\"level\":4,\"page\":1},{\"anchor\":\"an-example-of-how-the-calculateadvantages-function-might-be-implemented-in-pytorch\",\"content\":\"An example of how the calculate_advantages function might be implemented in PyTorch:\",\"level\":4,\"page\":1},{\"anchor\":\"an-example-of-how-the-getrewards-function-might-be-implemented-in-pytorch\",\"content\":\"An example of how the get_rewards function might be implemented in PyTorch:\",\"level\":4,\"page\":1},{\"anchor\":\"what-rewards-and-predictions-are-in-the-context-of-training-a-language-model-with-prompts-human-raters-using-ppo\",\"content\":\"What rewards and predictions are, in the context of training a language model with prompts, human raters, using PPO\",\"level\":4,\"page\":1},{\"anchor\":\"an-example-of-how-the-ppo-loss-can-be-low-for-a-highscoring-response-and-accurate-predictions-in-pytorch\",\"content\":\"An example of how the PPO loss can be low for a high-scoring response and accurate predictions in PyTorch:\",\"level\":4,\"page\":1},{\"anchor\":\"an-example-of-how-the-ppo-loss-can-be-high-for-a-lowscoring-response-and-inaccurate-predictions-in-pytorch\",\"content\":\"An example of how the PPO loss can be high for a low-scoring response and inaccurate predictions in PyTorch\",\"level\":4,\"page\":1},{\"anchor\":\"what-are-surrogate-and-clipping-loss-and-why-do-we-need-them\",\"content\":\"What are surrogate and clipping loss, and why do we need them?\",\"level\":4,\"page\":1},{\"anchor\":\"an-example-of-how-to-calculate-advantages-for-a-highscoring-response-and-accurate-predictions-in-pytorch\",\"content\":\"An example of how to calculate advantages for a high-scoring response and accurate predictions in PyTorch\",\"level\":4,\"page\":1},{\"anchor\":\"a-sample-dataset-for-language-model-training-using-ppo\",\"content\":\"A sample dataset for language model training using PPO\",\"level\":4,\"page\":1},{\"anchor\":\"conclusion\",\"content\":\"Conclusion\",\"level\":4,\"page\":1}]","expandText":"Expand Table of Contents","collapseText":"Collapse Table of Contents"};
/* ]]> */
</script>
<script type='text/javascript' src='../../wp-content/plugins/kadence-blocks/includes/assets/js/kb-table-of-contents.min.js%3Fver=3.0.27' id='kadence-blocks-tableofcontents-js'></script>
</body>

</html>
